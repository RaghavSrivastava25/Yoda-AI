{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# This script installs a list of Python packages using the pip package manager.\n",
        "\n",
        "# Import necessary modules for installing packages.\n",
        "import subprocess\n",
        "\n",
        "# List of packages to be installed.\n",
        "packages_to_install = [\n",
        "    'google-search-results',    # Provides an interface to fetch Google Search results.\n",
        "    'langchain',                # A library for handling natural language processing tasks.\n",
        "    'sentence_transformers',    # Utilizes transformer models for sentence embeddings.\n",
        "    'protobuf==3.20.0',         # Protocol Buffers - Google's data interchange format.\n",
        "    'llama-cpp-python',         # Python bindings for the LLAMA-CPP library.\n",
        "    'gpt4all',                  # A library for accessing GPT-4 based language models.\n",
        "    'faiss-cpu',                # A library for efficient similarity search and clustering of dense vectors.\n",
        "    'pydantic==1.10.11',        # Data validation and settings management using Python type annotations.\n",
        "    'typing-inspect==0.8.0',    # Tools for runtime inspection of types in Python code.\n",
        "    'typing_extensions==4.5.0', # Back-ported and experimental type hints for Python 3.6+.\n",
        "    'requests',                 # A library for making HTTP requests in Python.\n",
        "    'beautifulsoup4'            # A tool for web scraping HTML and XML documents.\n",
        "]\n",
        "\n",
        "# Loop through the list of packages and install them using pip.\n",
        "for package in packages_to_install:\n",
        "    subprocess.run(['pip', 'install', package])\n",
        "\n",
        "# Print a message indicating the successful installation of packages.\n",
        "print(\"All specified packages have been successfully installed.\")"
      ],
      "metadata": {
        "id": "9EWEtyDqusuN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing required modules and classes for the LangChain application.\n",
        "\n",
        "# Importing embeddings module for handling Hugging Face embeddings.\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "\n",
        "# Importing a callback handler for streaming standard output during execution.\n",
        "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
        "\n",
        "# Importing modules for LLMS (Language Learning Model System) components.\n",
        "from langchain.llms import GPT4All, LlamaCpp\n",
        "\n",
        "# Importing required built-in modules.\n",
        "import os             # For interacting with the operating system.\n",
        "import argparse       # For parsing command-line arguments.\n",
        "import time           # For working with time-related operations.\n",
        "\n",
        "# Importing modules related to different components of the LangChain application.\n",
        "from langchain.chains import RetrievalQA                # Chain module for Retrieval-based Question Answering.\n",
        "from langchain.document_loaders import TextLoader       # For loading text documents.\n",
        "from langchain.text_splitter import CharacterTextSplitter  # For splitting text into characters.\n",
        "from langchain.memory import ConversationBufferMemory   # Memory module for conversation buffers.\n",
        "from langchain.vectorstores import FAISS                # For utilizing FAISS vector store.\n",
        "\n",
        "# Importing a module for interfacing with Google Search API.\n",
        "from serpapi import GoogleSearch\n",
        "\n",
        "# Importing the requests module for making HTTP requests.\n",
        "import requests\n",
        "\n",
        "# Importing BeautifulSoup for parsing HTML documents.\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# Importing the CallbackManager class for managing callback functions.\n",
        "from langchain.callbacks.manager import CallbackManager\n",
        "\n",
        "# Importing the PromptTemplate class for managing prompt templates.\n",
        "from langchain import PromptTemplate"
      ],
      "metadata": {
        "id": "a-z3HiqPs-NU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating an instance of the TextLoader class to load text from a file.\n",
        "loader = TextLoader(\"source_documents/raghav.txt\")\n",
        "\n",
        "# Loading documents using the TextLoader instance.\n",
        "documents = loader.load()\n",
        "\n",
        "# Creating an instance of the CharacterTextSplitter class for splitting text into chunks.\n",
        "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
        "\n",
        "# Splitting the loaded documents into chunks using the TextSplitter instance.\n",
        "texts = text_splitter.split_documents(documents)"
      ],
      "metadata": {
        "id": "wsjrdfJ8tACZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating an instance of HuggingFaceEmbeddings with a specific model name.\n",
        "embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
        "\n",
        "# Using the HuggingFaceEmbeddings instance to generate embeddings for the loaded texts.\n",
        "# These embeddings will be used for semantic similarity calculations.\n",
        "# The generated embeddings can be later used for efficient retrieval.\n",
        "db = FAISS.from_documents(texts, embeddings)\n",
        "\n",
        "# Creating a retriever instance from the FAISS vector store.\n",
        "# This retriever is used for efficient similarity search and retrieval of documents.\n",
        "retriever = db.as_retriever()"
      ],
      "metadata": {
        "id": "v7pB2-fvtAF0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating an instance of CallbackManager with a list containing a StreamingStdOutCallbackHandler.\n",
        "# CallbackManager manages callback functions during LLMS (Language Learning Model System) execution.\n",
        "callback_manager = CallbackManager([StreamingStdOutCallbackHandler()])\n",
        "\n",
        "# Creating an instance of the GPT4All class (a Language Learning Model) with specified parameters.\n",
        "llm = GPT4All(\n",
        "    model=\"/Users/raghavsrivastava/Desktop/privateGPT-main/groovy.bin\",  # Path to the GPT-4 model file.\n",
        "    callback_manager=callback_manager,  # Assigning the CallbackManager instance.\n",
        "    verbose=True,  # Enabling verbose mode for more detailed output.\n",
        ")"
      ],
      "metadata": {
        "id": "-0IQz4yrtAJN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# A template string for generating prompts that involve answering questions based on text.\n",
        "template = \"\"\"Answer the question based on the text (.txt) file given to you.\n",
        "If the required answer is not specified in the\n",
        "text then respond with \"IDK\".\n",
        "\n",
        "{context}\n",
        "\n",
        "Question: {question}\n",
        "\n",
        "Answer: \"\"\"\n",
        "\n",
        "# Creating an instance of PromptTemplate for generating prompts with dynamic variables.\n",
        "# The input_variables parameter defines placeholders that can be replaced with actual values.\n",
        "# The template parameter specifies the template string to be used for generating prompts.\n",
        "prompt_template = PromptTemplate(\n",
        "    input_variables=[\"question\", \"context\"],  # List of input variables used in the template.\n",
        "    template=template  # The template string for generating prompts.\n",
        ")"
      ],
      "metadata": {
        "id": "lznxv8GZtAMK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining a dictionary that holds keyword arguments for specifying the chain type.\n",
        "# In this case, the \"prompt\" key is used to associate the defined prompt_template with the chain type.\n",
        "chain_type_kwargs = {\n",
        "    \"prompt\": prompt_template  # The \"prompt_template\" will be used for generating prompts in the chain.\n",
        "}"
      ],
      "metadata": {
        "id": "f5uabGWotAPe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a RetrievalQA instance from a specified chain type configuration.\n",
        "\n",
        "# The \"qa\" variable will hold the RetrievalQA instance.\n",
        "# The \"RetrievalQA.from_chain_type\" method is used to create an instance from a specific chain type.\n",
        "\n",
        "# The \"llm\" parameter specifies the Language Learning Model (LLM) instance to be used.\n",
        "# The \"chain_type\" parameter specifies the chain type configuration name (\"stuff\" in this case).\n",
        "# The \"retriever\" parameter specifies the retriever instance used for document retrieval.\n",
        "\n",
        "# The \"return_source_documents\" parameter indicates whether to include source documents in the output.\n",
        "# The \"chain_type_kwargs\" parameter provides additional keyword arguments for the chain type.\n",
        "\n",
        "qa = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    chain_type=\"stuff\",\n",
        "    retriever=retriever,\n",
        "    return_source_documents=True,\n",
        "    chain_type_kwargs=chain_type_kwargs\n",
        ")"
      ],
      "metadata": {
        "id": "KU-bKA5QtASc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qa.run"
      ],
      "metadata": {
        "id": "Nhr1bBh9tAVk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Taking user input to set the value of the \"prompt\" variable.\n",
        "\n",
        "# The \"input\" function is used to display the given prompt string (\"prompt:\")\n",
        "# and to receive user input as a string. The input is stored in the \"prompt\" variable.\n",
        "prompt = input(str(\"prompt:\"))"
      ],
      "metadata": {
        "id": "2uffgdMWtVlz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Writing the prompt and answer to an output file.\n",
        "\n",
        "# The \"output_file_path\" variable holds the path to the output file to be created or appended.\n",
        "output_file_path = \"raghav.txt\"\n",
        "\n",
        "# Opening the output file in \"append\" mode using a context manager.\n",
        "# The \"output_file\" variable represents the opened file.\n",
        "with open(output_file_path, \"a\") as output_file:\n",
        "    # Generating a response by invoking the \"qa\" instance with the user input prompt.\n",
        "    res = qa(prompt)\n",
        "    answer = res['result']  # Extracting the answer from the response.\n",
        "\n",
        "    # Writing the prompt and answer to the output file.\n",
        "    output_file.write(\"Prompt:\\n\")\n",
        "    output_file.write(prompt + \"\\n\\n\")\n",
        "    output_file.write(\"Answer:\\n\")\n",
        "    output_file.write(answer + \"\\n\\n\")"
      ],
      "metadata": {
        "id": "w6aHFKoztVo_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to fetch data from a given URL using the requests library.\n",
        "\n",
        "# The function \"getdata\" takes a single parameter \"url\", which is the URL of the website to fetch data from.\n",
        "def getdata(url):\n",
        "    # Sending a GET request to the specified URL using the \"requests.get\" function.\n",
        "    r = requests.get(url)\n",
        "\n",
        "    # Returning the text content of the response.\n",
        "    # This will be the HTML content of the page as a string.\n",
        "    return r.text"
      ],
      "metadata": {
        "id": "hoZNF4vrtVr8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "while True:\n",
        "    prompt = input(\"prompt:\")\n",
        "\n",
        "    # Retrieve answer using the previously configured QA instance\n",
        "    res = qa(prompt)\n",
        "    answer = res['result']\n",
        "\n",
        "    # Output results to a file\n",
        "    with open(output_file_path, \"a\") as output_file:\n",
        "        output_file.write(\"Prompt:\\n\")\n",
        "        output_file.write(prompt + \"\\n\\n\")\n",
        "\n",
        "        # Check if \"IDK\" is not in the answer\n",
        "        if \"IDK\" not in answer:\n",
        "            output_file.write(\"Answer:\\n\")\n",
        "            output_file.write(answer + \"\\n\\n\")\n",
        "        else:\n",
        "            # If \"IDK\" is in the answer, perform a Google search\n",
        "            params = {\n",
        "                \"engine\": \"google\",\n",
        "                \"q\": prompt,\n",
        "                \"location\": \"Seattle-Tacoma, WA, Washington, United States\",\n",
        "                \"api_key\": \"8ba225e0c4c155a4cf4f72fb31a87f6f28193c023a1ebe496e3627aef582a347\",\n",
        "                \"output\": \"json|html\"\n",
        "            }\n",
        "\n",
        "            # Perform a Google search using the SerpApi library\n",
        "            search = GoogleSearch(params)\n",
        "            results = search.get_dict()\n",
        "            organic_results = results[\"organic_results\"]\n",
        "\n",
        "            # Extract and append relevant data from search results to the output file\n",
        "            for i in organic_results:\n",
        "                if i['position'] == 1:\n",
        "                    url = i['link']\n",
        "                    htmldata = getdata(url)\n",
        "                    soup = BeautifulSoup(htmldata, \"html.parser\")\n",
        "                    for data in soup.find_all(\"p\"):\n",
        "                        with open(\"raghav.txt\", \"a\") as file:\n",
        "                            file.write(str(data) + \"\\n\")\n",
        "                            print(\"Data scraped and appended to 'raghav.txt' successfully.\")"
      ],
      "metadata": {
        "id": "fD6idMTEtVvQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Iq4cIdAJtV1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ihmm-wYrtV4g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "baV48GgTtV9m"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}